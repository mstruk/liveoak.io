= Mongo Resource
:awestruct-layout: two-column
:toc:
:toc-placement!:

toc::[]

Mongo module provides REST API to underlying MongoDB.

== Features

Mongo module provides a REST endpoint that exposes the data (JSON documents in collections), and the meta data (collections and their settings) in a JSON format, providing CRUD and querying support.

JSON documents can also refer to other JSON documents using resource references, and it's possible to expand such resource references and retrieve them nested within original JSON document.

Using 'fields' url query parameter client can <<controlling-which-fields-to-return,control which fields to return>>, and how deep to expand object hierarchies.

Client can use 'sort' query parameter for <<sorting,sorting results>>, and 'offset', and 'limit' query parameters for <<pagination,pagination>>.

Using 'q' url query parameter a query can be passed in a http://docs.mongodb.org/manual/reference/operator/query[Mongo DB JSON query syntax] to perform <<querying,querying>>.

There is also a special '_aggregate' collection endpoint for <<performing-aggregating-queries,performing aggregating queries>> on collections.

== Configuration

Mongo service is automatically made available to applications through extensions mechanism.

There is a file mongo.json in $LIVEOAK_HOME/conf/extensions directory which triggers installation of MongoExtension.


To make use of the extension, an application has to configure a resource of type 'mongo' in its application.json file e.g.:

[source,json]
----
{
  resources: {
    data: {
      type: 'mongo',
      config: {
        db: 'test',
        servers: [
          {
            host: 'localhost',
            port: 5432
          }
        ]
      }
    }
  }
}
----

In this case we bind a new 'mongo' resource to /APP_NAME/data endpoint, where APP_NAME is the name of our application.

The available configuration options are:

[source,json]
----
{
  db: 'test',
  servers: [
    {
      host: 'localhost',
      port: 5432
    }
  ],
  credentials: [
    {
      mechanism: 'MONGODB-CR',
      username: 'test',
      password: 'test',
      database: 'test'
    }
  ],
  WriteConcern: {
    w: 1,
    wTimeout: 10000,
    j: true,
    fsync: true,
    continueOnErrorForInsert: false
  },
  ReadPreference: {
    type: 'primaryPreferred',
    tags: {
      tag1: 'value1'
    },
    tags: {
      tag2: 'value2'
    }
  },
  MongoClientOptions: {
    description: '${APP_NAME}',
    connectionsPerHost: 100,
    threadsAllowedToBlockForConnectionMultiplier: 5,
    maxWaitTime: 120000,
    connectTimeout: 10000,
    socketKeepAlive: false,
    autoConnectRetry: false,
    maxAutoConnectRetryTime: 0,
    cursorFinalizerEnabled: true,
    alwaysUseMBeans: false
  }
}
----

TODO make naming of properties consistent: write-concern, read-preference, mongo-client-options

* db
+
> MongoDB database name

* servers
+
> list of servers in the http://docs.mongodb.org/manual/replication[replica set], each server identified with a host, and a port.

* credentials
+
> list of credentials for connecting to the server - only required if authentication is configured on the servers

** mechanism
+
> authentication mechanism to use. Possible values are 'MONGODB-CR', and 'GSSAPI'

** username
+
> a login / username to use

** password
+
> a password to authenticate with - only used when mechanism is MONGODB-CR

** database
+
> database where user is defined - only used when mechanism is MONGODB-CR

TODO: how does that work ... why is credentials not part of 'servers'?



* WriteConcern
+
> set of properties that control behavior of write operations
+
** w
+
> write acknowledgement (default value is 1)
+
> * -1 ... don't even report network errors
> *  0 ... don't wait for acknowledgement from the server
> *  1 ... wait for acknowledgement, but don't wait for secondaries to replicate
> * 2+ ... wait for one or more secondaries to also acknowledge

** wTimeout
+
> timeout for write operation - how long to wait for slaves before failing (default value is 10000)
+
> * 0 ... indefinite
> * greater than 0: number of ms to wait

** j
+
> wait for group commit to journal (default value is true)

** fsync
+
> perform native OS sync to disk (default value is true)

** continueOnErrorForInsert
+
> should batch operations continue or fail fast if error occurs (default value is false)

* ReadPreference
+
> set of properties that control behavior of read operations - preferred replica set members to which a query or command can be sent
+
** type
+
> type value can be one of:
+
> * primary
> * secondary
> * secondaryPreferred
> * primaryPreferred
> * nearest

** tags
+
> a key value pair representing a tag, and its value as a discriminator for identifying secondary replica set members

* MongoClientOptions  
** description
+
> name to be used for logging and jmx
** connectionsPerHost
+
> The maximum number of pooled connections allowed per host for this MongoClient instance.
** threadsAllowedToBlockForConnectionMultiplier
+
> a multiplier ... when multiplied with the connectionsPerHost setting, gives the maximum number of threads that may be waiting for a connection to become available from the pool
** maxWaitTime
+
> The maximum wait time in milliseconds that a thread may wait for a connection to become available - value of 0 means don't wait, -1 means wait indefinitely
** connectTimeout
+
> The connect timeout in milliseconds.  A value of 0 means no timeout.
** socketKeepAlive
+
> This flag controls the socket keep alive feature that keeps a connection alive through firewalls. Default value is 'false'
** autoConnectRetry
+ 
> if value is true, then in case a connection can't be established the client will try to reconnect
** maxAutoConnectRetryTime
+
> if value is greater than 0, and autoConnectRetry is true that is the timeout value for trying to reconnect. If value is 0 the default reconnect timeout of 15s is used
** cursorFinalizerEnabled
+
> it true finalize() method on DBCursor is used to clean up any unclosed cursors
** alwaysUseMBeans
+
> if false MXBeans will be used rather than standard MBeans.


== REST API

In LiveOak resources are structured in a very simple way. Each application gets its namespace under root. It further partitions this namespace to subcontexts where each subcontext is handled by a resource registered to that subcontext.

Following the configuration example above, Mongo root endpoint is available at /APP_NAME/data.

Let's assume our application name is demo-app, and is deployed to a LiveOak server running on localhost. We can then access it at:

http://localhost:8080/demo-app/data

We'll refer to this as 'Mongo endpoint'.

We use 'curl' in the examples below. For brewity some non-essential parameters are left out, but may under some circumstances be required - depending on application configuration.

Specifically, it may be necessary to use

        -H 'Content-Type: application/json'

when performing POST / PUT operations.

And it may sometimes be necessary to use

        -H 'Accept: application/json'


== Listing collections

GET http://localhost:8080/demo-app/data

----
$ curl http://localhost:8080/demo-app/data
{
  "id" : "data",
  "self" : {
    "href" : "/demo-app/data"
  },
  "type" : "database",
  "count" : 0
}
----

All resources contain at least an 'id' field, and a 'self' field containing an 'href'. The first one is a convenience, since the self/href already uniquely identifies a resource.

Collection resources contain a 'count' field, which returns a number of children. In this case there are no children, as there are no collections yet.

The 'type' field helps tools determine the contract to use when communicating with this REST endpoint.

If some collections were already present in the database, then we would also receive a 'members' field listing the child items.

For example we might receive:

[source,json]
----
{
  "id" : "data",
  "self" : {
    "href" : "/demo-app/data"
  },
  "type" : "database",
  "count" : 2,
  "members" : [ {
    "id" : "rooms",
    "self" : {
      "href" : "/demo-app/data/rooms"
    }
  }, {
    "id" : "users",
    "self" : {
      "href" : "/demo-app/data/users"
    }
  } ]
}
----

For children we only receive object stubs with identity information.

== Creating a collection

To create a new collection we POST a JSON message describing the collection to Mongo endpoint.

POST http://localhost:8080/demo-app/data

----
$ curl -X POST -H "Content-Type: application/json" http://localhost:8080/demo-app/data -T - << EOF
{
  "id" : "users"
}
EOF
----

All we have to specify is the name of the new collection as a resource id.

We get back a JSON describing the created collection:
[source,json]
----
{
  "id" : "users",
  "self" : {
    "href" : "/demo-app/data/users"
  },
  "type" : "collection",
  "count" : 0,
  "capped" : false
}
----

TODO: As opposed to PgSql endpoint here we don't have any collection schema vs. collection data separation. The amount of collection schema meta info is small enough to allow that.
But looks like we violate the 'return a full state of the object approach'. We should be returning size, max, and autoIndexId regardless of whether capped is true or not.

We can specify additional meta info for the new collection: 
[source,json]
----
{
  "id" : "users",
  "capped" : true,
  "size" : 1000,
  "max" : 100000,
  "autoIndexId" : true
}
----

The meaning of these properties is as follows:

* capped 
+
> if the collection is capped (default value is false) - see http://docs.mongodb.org/manual/core/capped-collections[Capped Collections]
* size
+
> collection size limit for capped collection in bytes (required for capped collections)
* max
+
> max number of documents limit for capped collection
* autoIndexId
+
> if unique index should automatically be created for _id column of a capped collection. Required to ensure uniqueness across databases in a replica set. Prior to MongoDB version 2.2 the default for this was false, since version 2.2 it is true.


== Retrieving a collection definition

TODO: currently there is no mechanism to only retrieve a collection definition.
The most one can do is filter out members:

GET http://localhost:8080/demo-app/data/TABLEID?fields=-members

TODO: that doesn't work have to use *,-members ... implement fields=-members to mean the same as fields=*,-members

curl http://localhost:8080/demo-app/data/users?fields=*,-members

TODO: links: [{rel: 'aggregate', href: '/demo-app/data/_aggregate'}]


== Dropping a table

DELETE http://localhost:8080/demo-app/data/TABLEID

    $ curl -X DELETE 'http://localhost:8080/demo-app/data/users'

    {
      "id" : "users",
      "self" : {
        "href" : "/demo-app/data/users"
      },
      "type" : "collection",
      "count" : 0,
      "capped" : false
    }

The returned status has no error-type section in it, meaning that the operation was successful - the table, and all the data it contained was removed.

TODO: Don't return any meta info in this case - no type, count, capped - it's redundant and quite irrelevant.

== Creating items

POST http://localhost:8080/demo-app/sqldata/TABLEID

    $ curl -v -X POST 'http://localhost:8080/demo-app/data/users' -T - << EOF
    {
      'nick': 'rabbit',
      'last_login': 0
    }
    EOF


In this case we did not specify an 'id' field - which means the endpoint will assign one.

If successful this returns the full state of newly created item including any fields that were autogenerated by endpoint.

[source,json]
----
{
  "id" : "ObjectId(\"541ac43099a8fbe3cb21492e\")",
  "self" : {
    "href" : "/demo-app/data/users/ObjectId%28%22541ac43099a8fbe3cb21492e%22%29"
  },
  "nick" : "rabbit",
  "last_login" : 0
}
----

TODO: what's the plan with ObjectId? 

== Hints

MongoDB uses hints as a mechanism to instruct the database which index to use when querying the collection in order to improve performance.

MongoDB uses indexes whenever it can, but sometimes there may be multiple possible indexes to use, and we want to make sure that the correct one is used. 

When performing a query a ‘hint’ parameter can be used to specify by name, or by index specification in JSON format which existing index to use. The hinted index has to already exist on the collection. 

To find out more about indexes see http://docs.mongodb.org/manual/indexes[MongoDB Indexes documentation].

Currently Mongo endpoint doesn’t provide any mechanism to create and manage indexes.
